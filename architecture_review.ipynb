{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import contextlib\n",
    "from models.common import (\n",
    "    C3,\n",
    "    C3SPP,\n",
    "    C3TR,\n",
    "    SPP,\n",
    "    SPPF,\n",
    "    Bottleneck,\n",
    "    BottleneckCSP,\n",
    "    C3Ghost,\n",
    "    C3x,\n",
    "    Classify,\n",
    "    Concat,\n",
    "    Contract,\n",
    "    Conv,\n",
    "    CrossConv,\n",
    "    DetectMultiBackend,\n",
    "    DWConv,\n",
    "    DWConvTranspose2d,\n",
    "    Expand,\n",
    "    Focus,\n",
    "    GhostBottleneck,\n",
    "    GhostConv,\n",
    "    Proto,\n",
    ")\n",
    "from models.experimental import MixConv2d\n",
    "from utils.general import LOGGER, check_version, check_yaml, colorstr, make_divisible, print_args\n",
    "from copy import deepcopy\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detect(nn.Module):\n",
    "    # YOLOv5 Detect head for detection models\n",
    "    stride = None  # strides computed during build\n",
    "    dynamic = False  # force grid reconstruction\n",
    "    export = False  # export mode\n",
    "\n",
    "    def __init__(self, nc=80, anchors=(), ch=(), inplace=True):  # detection layer\n",
    "        super().__init__()\n",
    "        self.nc = nc  # number of classes\n",
    "        self.no = nc + 5  # number of outputs per anchor\n",
    "        self.nl = len(anchors)  # number of detection layers\n",
    "        self.na = len(anchors[0]) // 2  # number of anchors\n",
    "        self.grid = [torch.empty(0) for _ in range(self.nl)]  # init grid\n",
    "        self.anchor_grid = [torch.empty(0) for _ in range(self.nl)]  # init anchor grid\n",
    "        self.register_buffer(\"anchors\", torch.tensor(anchors).float().view(self.nl, -1, 2))  # shape(nl,na,2)\n",
    "        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, 1) for x in ch)  # output conv\n",
    "        self.inplace = inplace  # use inplace ops (e.g. slice assignment)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = []  # inference output\n",
    "        for i in range(self.nl):\n",
    "            x[i] = self.m[i](x[i])  # conv\n",
    "            bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)\n",
    "            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()\n",
    "\n",
    "            if not self.training:  # inference\n",
    "                if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:\n",
    "                    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)\n",
    "\n",
    "                if isinstance(self, Segment):  # (boxes + masks)\n",
    "                    xy, wh, conf, mask = x[i].split((2, 2, self.nc + 1, self.no - self.nc - 5), 4)\n",
    "                    xy = (xy.sigmoid() * 2 + self.grid[i]) * self.stride[i]  # xy\n",
    "                    wh = (wh.sigmoid() * 2) ** 2 * self.anchor_grid[i]  # wh\n",
    "                    y = torch.cat((xy, wh, conf.sigmoid(), mask), 4)\n",
    "                else:  # Detect (boxes only)\n",
    "                    xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)\n",
    "                    xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy\n",
    "                    wh = (wh * 2) ** 2 * self.anchor_grid[i]  # wh\n",
    "                    y = torch.cat((xy, wh, conf), 4)\n",
    "                z.append(y.view(bs, self.na * nx * ny, self.no))\n",
    "\n",
    "        return x if self.training else (torch.cat(z, 1),) if self.export else (torch.cat(z, 1), x)\n",
    "\n",
    "    def _make_grid(self, nx=20, ny=20, i=0, torch_1_10=check_version(torch.__version__, \"1.10.0\")):\n",
    "        d = self.anchors[i].device\n",
    "        t = self.anchors[i].dtype\n",
    "        shape = 1, self.na, ny, nx, 2  # grid shape\n",
    "        y, x = torch.arange(ny, device=d, dtype=t), torch.arange(nx, device=d, dtype=t)\n",
    "        yv, xv = torch.meshgrid(y, x, indexing=\"ij\") if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility\n",
    "        grid = torch.stack((xv, yv), 2).expand(shape) - 0.5  # add grid offset, i.e. y = 2.0 * x - 0.5\n",
    "        anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)\n",
    "        return grid, anchor_grid\n",
    "\n",
    "\n",
    "class Segment(Detect):\n",
    "    # YOLOv5 Segment head for segmentation models\n",
    "    def __init__(self, nc=80, anchors=(), nm=32, npr=256, ch=(), inplace=True):\n",
    "        super().__init__(nc, anchors, ch, inplace)\n",
    "        self.nm = nm  # number of masks\n",
    "        self.npr = npr  # number of protos\n",
    "        self.no = 5 + nc + self.nm  # number of outputs per anchor\n",
    "        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, 1) for x in ch)  # output conv\n",
    "        self.proto = Proto(ch[0], self.npr, self.nm)  # protos\n",
    "        self.detect = Detect.forward\n",
    "\n",
    "    def forward(self, x):\n",
    "        p = self.proto(x[0])\n",
    "        x = self.detect(self, x)\n",
    "        return (x, p) if self.training else (x[0], p) if self.export else (x[0], p, x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def parse_model(d, ch):  # model_dict, input_channels(3)\n",
    "    # Parse a YOLOv5 model.yaml dictionary\n",
    "    # LOGGER.info(f\"\\n{'':>3}{'from':>18}{'n':>3}{'params':>10}  {'module':<40}{'arguments':<30}\")\n",
    "    anchors, nc, gd, gw, act, ch_mul = (\n",
    "        d[\"anchors\"],\n",
    "        d[\"nc\"],\n",
    "        d[\"depth_multiple\"],\n",
    "        d[\"width_multiple\"],\n",
    "        d.get(\"activation\"),\n",
    "        d.get(\"channel_multiple\"),\n",
    "    )\n",
    "    if act:\n",
    "        Conv.default_act = eval(act)  # redefine default activation, i.e. Conv.default_act = nn.SiLU()\n",
    "        # LOGGER.info(f\"{colorstr('activation:')} {act}\")  # print\n",
    "    if not ch_mul:\n",
    "        ch_mul = 8\n",
    "    na = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors  # number of anchors\n",
    "    no = na * (nc + 5)  # number of outputs = anchors * (classes + 5)\n",
    "\n",
    "    layers, save, c2 = [], [], ch[-1]  # layers, savelist, ch out\n",
    "    for i, (f, n, m, args) in enumerate(d[\"backbone\"] + d[\"head\"]):  # from, number, module, args\n",
    "        m = eval(m) if isinstance(m, str) else m  # eval strings\n",
    "        for j, a in enumerate(args):\n",
    "            with contextlib.suppress(NameError):\n",
    "                args[j] = eval(a) if isinstance(a, str) else a  # eval strings\n",
    "\n",
    "        n = n_ = max(round(n * gd), 1) if n > 1 else n  # depth gain\n",
    "        if m in {\n",
    "            Conv,\n",
    "            GhostConv,\n",
    "            Bottleneck,\n",
    "            GhostBottleneck,\n",
    "            SPP,\n",
    "            SPPF,\n",
    "            DWConv,\n",
    "            MixConv2d,\n",
    "            Focus,\n",
    "            CrossConv,\n",
    "            BottleneckCSP,\n",
    "            C3,\n",
    "            C3TR,\n",
    "            C3SPP,\n",
    "            C3Ghost,\n",
    "            nn.ConvTranspose2d,\n",
    "            DWConvTranspose2d,\n",
    "            C3x,\n",
    "        }:\n",
    "            c1, c2 = ch[f], args[0]\n",
    "            if c2 != no:  # if not output\n",
    "                c2 = make_divisible(c2 * gw, ch_mul)\n",
    "\n",
    "            args = [c1, c2, *args[1:]]\n",
    "            if m in {BottleneckCSP, C3, C3TR, C3Ghost, C3x}:\n",
    "                args.insert(2, n)  # number of repeats\n",
    "                n = 1\n",
    "        elif m is nn.BatchNorm2d:\n",
    "            args = [ch[f]]\n",
    "        elif m is Concat:\n",
    "            c2 = sum(ch[x] for x in f)\n",
    "        # TODO: channel, gw, gd\n",
    "        elif m in {Detect, Segment}:\n",
    "            args.append([ch[x] for x in f])\n",
    "            if isinstance(args[1], int):  # number of anchors\n",
    "                args[1] = [list(range(args[1] * 2))] * len(f)\n",
    "            if m is Segment:\n",
    "                args[3] = make_divisible(args[3] * gw, ch_mul)\n",
    "        elif m is Contract:\n",
    "            c2 = ch[f] * args[0] ** 2\n",
    "        elif m is Expand:\n",
    "            c2 = ch[f] // args[0] ** 2\n",
    "        else:\n",
    "            c2 = ch[f]\n",
    "\n",
    "        m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args)  # module\n",
    "        t = str(m)[8:-2].replace(\"__main__.\", \"\")  # module type\n",
    "        np = sum(x.numel() for x in m_.parameters())  # number params\n",
    "        m_.i, m_.f, m_.type, m_.np = i, f, t, np  # attach index, 'from' index, type, number params\n",
    "        # LOGGER.info(f\"{i:>3}{str(f):>18}{n_:>3}{np:10.0f}  {t:<40}{str(args):<30}\")  # print\n",
    "        save.extend(x % i for x in ([f] if isinstance(f, int) else f) if x != -1)  # append to savelist\n",
    "        layers.append(m_)\n",
    "        if i == 0:\n",
    "            ch = []\n",
    "        ch.append(c2)\n",
    "    return nn.Sequential(*layers), sorted(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "cfg = \"models/yolov5s_twoheads.yaml\"\n",
    "ch = 3\n",
    "\n",
    "yaml_file = Path(cfg).name\n",
    "with open(cfg, encoding=\"ascii\", errors=\"ignore\") as f:\n",
    "    yaml_l = yaml.safe_load(f)\n",
    "ch = yaml_l[\"ch\"] = yaml_l.get(\"ch\",ch)\n",
    "model, save = parse_model(deepcopy(yaml_l), ch=[ch])\n",
    "names = [str(i) for i in range(yaml_l[\"nc\"])]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
